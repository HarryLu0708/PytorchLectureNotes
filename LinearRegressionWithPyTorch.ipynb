{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression with PyTorch\n",
        "- 定义模型\n",
        "- 定义损失函数\n",
        "- SGD"
      ],
      "metadata": {
        "id": "DL_V4aVMYVM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 开发流程\n",
        "- 准备数据集Dataset\n",
        "- 使用类设计模型（从nn.Module继承）\n",
        "- 构建损失函数与优化器\n",
        "- 训练循环：前馈，反馈，更新"
      ],
      "metadata": {
        "id": "CeFd2EfAY0Mc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu15QHN2X7Gl"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = torch.Tensor([[1.],[2.],[3.]])\n",
        "y_data = torch.Tensor([[2.],[4.],[6.]])"
      ],
      "metadata": {
        "id": "I-x4K92bZQco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch开发重点\n",
        "- 构造计算图\n",
        "- 确定权重和偏置量的大小\n",
        "- 我们需要知道x的维度和y_hat的维度\n",
        "- 计算后，在loss值进行反向传播\n",
        "- loss是一个标量"
      ],
      "metadata": {
        "id": "iMx6jeMWfPk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    # just do it\n",
        "    super(LinearModel,self).__init__()\n",
        "    # construct an object includes: weight and bias\n",
        "    self.linear = torch.nn.Linear(1,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_pred = self.linear(x)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "rsgpzKdUZY_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化模型\n",
        "model = LinearModel()\n",
        "# 构造损失函数\n",
        "criterion = torch.nn.MSELoss(size_average=False)\n",
        "# 构造优化器\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_FLRVZtiVUl",
        "outputId": "f09b94e2-f04a-4115-9e6c-8b53d8b215ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = [\n",
        "  torch.optim.SGD(model.parameters(),lr=0.01),\n",
        "  torch.optim.Adagrad(model.parameters(),lr=0.01),\n",
        "  torch.optim.Adam(model.parameters(),lr=0.01),\n",
        "  torch.optim.Adamax(model.parameters(),lr=0.01),\n",
        "  torch.optim.ASGD(model.parameters(),lr=0.01),\n",
        "  #torch.optim.LBFGS(model.parameters(),lr=0.01),\n",
        "  torch.optim.RMSprop(model.parameters(),lr=0.01),\n",
        "  torch.optim.Rprop(model.parameters(),lr=0.01)\n",
        "]"
      ],
      "metadata": {
        "id": "XEIv3eVRVmK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练循环\n",
        "for epoch in range(100):\n",
        "  y_pred = model(x_data)\n",
        "  loss = criterion(y_pred,y_data)\n",
        "  print(epoch,loss)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ponyYS6SjB05",
        "outputId": "d462a96c-1810-4d25-8262-717c7dd4f797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor(105.8874, grad_fn=<MseLossBackward0>)\n",
            "1 tensor(47.1389, grad_fn=<MseLossBackward0>)\n",
            "2 tensor(20.9857, grad_fn=<MseLossBackward0>)\n",
            "3 tensor(9.3431, grad_fn=<MseLossBackward0>)\n",
            "4 tensor(4.1601, grad_fn=<MseLossBackward0>)\n",
            "5 tensor(1.8527, grad_fn=<MseLossBackward0>)\n",
            "6 tensor(0.8256, grad_fn=<MseLossBackward0>)\n",
            "7 tensor(0.3683, grad_fn=<MseLossBackward0>)\n",
            "8 tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
            "9 tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
            "10 tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
            "11 tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
            "12 tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
            "13 tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
            "14 tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "15 tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "16 tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "17 tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "18 tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "19 tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "20 tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "21 tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "22 tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "23 tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "24 tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "25 tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "26 tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "27 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "28 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "29 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "30 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "31 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "32 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "33 tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "34 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "35 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "36 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "37 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "38 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "39 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "40 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "41 tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "42 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "43 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "44 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "45 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "46 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "47 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "48 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "49 tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "50 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "51 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "52 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "53 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "54 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "55 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "56 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "57 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "58 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "59 tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "60 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "61 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "62 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "63 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "64 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "65 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "66 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "67 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "68 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "69 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "70 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "71 tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "72 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "73 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "74 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "75 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "76 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "77 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "78 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "79 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "80 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "81 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "82 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "83 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "84 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "85 tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "86 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "87 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "88 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "89 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "90 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "91 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "92 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "93 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "94 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "95 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "96 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "97 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "98 tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "99 tensor(0.0004, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 流程\n",
        "- 计算y_hat\n",
        "- 计算loss值\n",
        "- 计算反向传播\n",
        "- 更新"
      ],
      "metadata": {
        "id": "G2l8GdB5j4BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 打印最终的权重和偏差值\n",
        "print('w=',model.linear.weight.item())\n",
        "print('b=',model.linear.bias.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRzN-b9Tj2ox",
        "outputId": "ea03666a-f0c2-447b-de6c-632f930d4160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w= 1.987217903137207\n",
            "b= 0.029056811705231667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建测试集并测试模型\n",
        "x_test = torch.Tensor([[4.0]])\n",
        "y_test = model(x_test)\n",
        "print(\"Test Result:\",y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6XhxW3dkVsR",
        "outputId": "2b9fc306-5cb0-4967-cac9-0e272b97761b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Result: tensor([[7.9779]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression Assignment"
      ],
      "metadata": {
        "id": "f-V-bD8xWdE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for optmizer in optimizers:\n",
        "  for epoch in range(100):\n",
        "    y_pred = model(x_data)\n",
        "    loss = criterion(y_pred,y_data)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optmizer.step()\n",
        "  print(\"w=\",model.linear.weight.item())\n",
        "  print(\"b=\",model.linear.bias.item())\n",
        "  x_test = torch.Tensor([4.0])\n",
        "  y_test = model(x_test)\n",
        "  print(\"Test:\",y_test)"
      ],
      "metadata": {
        "id": "X9QYNkPikfze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df22e8a-37bb-4500-a8eb-043f4f391c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w= 1.9999886751174927\n",
            "b= 2.578936801000964e-05\n",
            "Test: tensor([8.0000], grad_fn=<ViewBackward0>)\n",
            "w= 2.000087261199951\n",
            "b= -0.0001939807116286829\n",
            "Test: tensor([8.0002], grad_fn=<ViewBackward0>)\n",
            "w= 2.000004529953003\n",
            "b= -9.156444866675884e-05\n",
            "Test: tensor([7.9999], grad_fn=<ViewBackward0>)\n",
            "w= 1.9999737739562988\n",
            "b= -2.6236462872475386e-05\n",
            "Test: tensor([7.9999], grad_fn=<ViewBackward0>)\n",
            "w= 1.999974012374878\n",
            "b= 4.508026904659346e-05\n",
            "Test: tensor([7.9999], grad_fn=<ViewBackward0>)\n",
            "w= 2.0000007152557373\n",
            "b= -1.2426154398781364e-06\n",
            "Test: tensor([8.0000], grad_fn=<ViewBackward0>)\n",
            "w= 1.999989628791809\n",
            "b= 1.803204395400826e-05\n",
            "Test: tensor([8.0000], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbHeflVCX28g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}